### 11_27

진격의 거인

주술회전

소드아트 온라인

죠죠의 기묘한 모험

어나더

스쿨데이즈

쓰르라미 울적에

격투맨 바키

노 건즈 라이프

종말의 발키리

닥터 스톤

괴물사변

도쿄 리벤져스

도쿄 구울

지옥락

노블레스

캐슬바니아

러브 데스 로봇

스프리건

도타: 용의 피

바스타드: 암흑의 파괴신

베르세르크

도로헤도로

사이코패스

카우보이 비밥

아카메가 벤다!

도로헤도로

살육의 천사

약속의 네버랜드

노리가미

아인

청의 엑소시스트

오버로드

아프로 사무라이

고블린 슬레이어

페이트 시리즈

소드가이 : 애니메이션

가이버 시리즈

야스케

B: 더 비기닝

일곱개의 대죄

블러드 오브 제우스

트레세: 도시의 수호자

데빌맨 시리즈

여섯 개의 주먹

간츠 시리즈

드래곤즈 도그마

파이어 펀치

원펀맨

가시나무왕

persistance context : 영속성 컨텍스트
영속성 컨테이너가 관리하고 있는 내용이다 라는 뜻
persistance 즉 영속화 라는 의미는 사라지지않고 지속 가능하다는 뜻이다. 
영속성 컨텍스트는 엔티티를 영구 저장하는 환경이다.
영속성 컨텍스트는 논리적인 개념이다.
영속성 컨텍스트는 엔티티 매니저를 생성할 때 하나 만들어진다.
영속성 컨텍스트는 엔티티 매니저를 통해서 접근한다.
엔티티 매니저는 영속성 컨텍스트에 접근할 수 있는 유일한 방법이다.
영속성 컨텍스트는 트랜잭션과 생명주기가 같다.
영속성 컨텍스트는 엔티티를 저장하는 가상의 데이터베이스라고 생각하면 된다.
영속성 컨텍스트는 내부에 캐시를 가지고 있다.
영속성 컨텍스트는 엔티티를 식별자 값으로 구분한다.
영속성 컨텍스트는 트랜잭션을 지원하는 쓰기 지연

영속성 컨텍스트는 persistance.xml이라는 파일로 설정해서 쓴다. 
META-INF/persistance.xml
persistence-unit name="hello"
persistence-unit name="hello" transaction-type="RESOURCE_LOCAL"
persistence-unit name="hello" transaction-type="JTA"
persistence-unit name="hello" transaction-type="JTA"

영속성 컨텍스트를 설정하거나 신경쓰지않아도 할 수 있었다. 
그게 어떻게 된 거냐면 스프링 부트 스타터 데이터 jpa 가 스프링부트가 persistance 에 대한 설정을
모두 처리해줬기 때문에 쉽게 사용할 수 있었던 것이다. 

영속성 컨텍스트는 엔티티를 식별자 값으로 구분한다
영속성 컨텍스트는 내부에 캐시를 가지고 있다.
영속성 컨텍스트는 엔티티를 식별자 값으로 구분한다.
영속성 컨텍스트는 트랜잭션을 지원하는 쓰기 지연 기능을 제공한다.
영속성 컨텍스트는 변경 감지 기능을 제공한다.
영속성 컨텍스트는 지연 로딩 기능을 제공한다.

serverTimezone=Asia/Seoul

datasource:
    url: jdbc:mysql://localhost:3306/jpashop?serverTimezone=Asia/Seoul
    username: root
    password: 1234
    driver-class-name: com.mysql.cj.jdbc.Driver

Test쪽 context 돌려보자 driver class 문제 생김 
build.gradle에 runtimeOnly 'mysql:mysql-connector-java' 추가해주자
실제로 context가 정상적으로 동작 하는데 using dialect: MySQL5Dialect 이라는 문구가 뜬다.

Using dialect H2Dialect 이라는 문구가 뜬다.
Dialect 라는 뜻은 방언이라고 해석이 되는데 Entity나 Re

쿼리를 알아서 맞춰주는게 dialect 의 일이다 . h2의 dialect 를 mysql dialect로 변경해준다. 

AuthorRepositoryTest 해봤는데 
No databaseSelected 처리가 나온다. 
book_manager

generated-ddl : true
hiberante:ddl-auto : create-drop

기존에는 h2 디비를 사용해서 기본값을 사용하지 않았는데 mysql을 쓰면서 generated-ddl : true
hiberante:ddl-auto : create-drop 을 사용하면서 기본값을 사용하게 되었다.

상용 db라서 generated-ddl : true 을 옵션으로 켜줘야되는것이다. 

ddl-auto : create-drop 은 테이블을 생성하고 사용한 다음에 drop을 해버리는 것이다.

create는 persistance에서 drop하고 띄우는데 
create-drop은 종료할때 drop하는 차이가 있다. 
업데이트를 하면 실제 클래스와 엔티티 부분을 반영해 변경되는 부분만 바뀌고 drop안함

initialization-mode: always
임베드 db이고 데이타 나 스키마 sql 파일이 resources 폴더 밑에 존재한다면 자동으로 로드시켜줬기 때문에 
우리가 기존 로직에선 별다른 설정 없이 사용할 수 있었다. 
mysql 환경에서 사용하면 임베디드 db의 경우에만 쓴다는거고 always는 항상 실행한다는 뜻이다.

데이터 초기화를 진행하지 않는다고 하면 운영 배포를 할 때는 데이터의 초기화를 하면 안되니깐 
만약에 initialization-mode로 always로 하고 스키마 파일이 있고 
ddl-auto가 create-drop이면 스키마 파일을 먼저 실행하고 그 다음에 create-drop을 실행한다.
그래서 스키마 파일을 실행하고 데이터를 넣어주면 데이터가 들어가 있는 상태로 실행이 된다.

스키마 sql 파일이 더욱 우선적으로 식행되기때문에 이니셜라이제이션 모드를 always로 해줘야한다.
우리는 schema-sql 
이 있으면 ddl auto는 무시된다고 한다. 

prePersistTest(); 
쿼리에 유니크 리졸트가 와야되는데 너무 많이 왔다 라고 한다. 
사실 이런 경우는 지금 우리가 테스트를 

클래스 상단에 @Transactional 어노테이션을 처리하면 롤백해주는 일을 해준다. 
Helloworld 메서드는 JPA metamodel must not be empty

helloworld 테스트가 webmvctest 슬라이스 테스트라고하는데 전체 테스틀르 하지않고 
웹 컨트롤러에서만 진행하기 때문에 JPA를 사용하는 부분은 빈으로 등록이 되지 않는다.
그래서 JPA를 사용하는 부분을 등록해줘야한다.
@MockBean(JpaMetaModelMappingContext.class) 를 추가해주면 된다.
헬로 월드 컨트롤러에서는 jpa가 필요가 없기 때문에 로딩을 할 수 없었던 건데 
목빈으로 해서 마치 있는 것 처럼 해주면서 해결할 수 있다. 

Book Manager에 있는 applcation EnableJpaAuditing 별도의 클래스로 생성해서 
JpaConfiguration 별도의 bean에서 로딩시켜주는 것이다. 

@Autowired
private WebApplicationContext context;

private MockMvc mockMvc;

@BeforeEach
void before() {
mockMvc = MockMvcBuilders
            .webAppContextSetup(context)
            .apply(springSecurity())
            .build();
}

자동으로 만들어줬던 mockmvc를 우리가 직접 해본 것이다. 

처리 방법에 있어서는 두가지가 있다.
실제로는 로딩이 된 줄 알았는데 Mockbean이라서 그런 걸 수도 있다 .
조금은 더 보편적인 방법을 사용하는게 좋을 수도 있다. 

crud테스트에서 생기는 not-null 문제 
@OneToOne(optional = false)

실제로는 one to one 기능이니 setbook(givenbook())으로 릴레이션 걸어주면 된다. 

crud테스트 2의 경우에는 실제로 단독으로 실행시키면 아무런 문제가 없는 테스트이다. 
서로 테스트가 영향을 주는 것 같다. 
bookRepository가 1번 아이디의 정보를가져왔는데 nulㅣ이라고 하는 것이다. 
h2 db에서는 시퀀스라고 사용하는데 GenerationType.IDENTITY를 사용하면
시퀀스를 사용하지 않고 자동으로 생성해준다.

@OneToOne(mappedBy = "book", cascade = CascadeType.ALL)
private BookReviewInfo bookReviewInfo;

book을 우리가 givenBook이라고해서 사용했다. save하면 auto increment가 되면서 id가 생성이 된다.
실제로 여기서 만든 값이 1이 되었었는데 
계속 증가해서 
1이 아니라 7이 되었다.

영속성 컨텍스트에서 가장 중요한 역할을 하고있는 엔티티매니저와 엔티티들을 관리하는 영속성 컨텍스트가 있다.
알아보도록 하자 

지난시간에는 기본적인 영속성 컨텍스트에 대해서 알아보았다. 사실 영속성 컨텍스트는 일종의 
jpa 컨테이너 안에서 동작하는 엔티티의 맥락을 관리하는걸 영속성 컨텍스트라고 한다. 
컨텍스트 안에서 일반적으로 엔티티는 생성되고 지워지고 조회된다. 그런 컨텍스트 안에서 가장 중요한 역할을
하는것이 엔티티 매니저이다. 
엔티티 매니저의 역할으 ㄹ알아보고 처리하느 ㄴ과정에서 캐시를 사용하는데 어떤식으로 활용하는지 살펴보면서 
영속성 컨텍스트에 대해서 알아보도록 하겠다. 

엔티티 매니저 역시 jpa에서 정의하고 있는 일종의 인터페이스이다. 

@SpringBootTest
public class EntityManagerTest {
    
        @Autowired
        private EntityManager entityManager;
    
        @Test
        void entityManagerTest() {
            System.out.println(entityManager.createQuery("select u from User u").getResultList();
        }
    }

유저 레포지터리에 findAll이라는 쿼리를 동작시키는 것이다. 
기존에 우리가 사용했던 쿼리 메소드 심플 jpa는 직접적으로 엔티티매니저를 사용하지 않아도 되도록
한번더 래핑을 해서 스프링에서 제공하는 걸 알 수 있다. 

스프링 데이터 jpa에서 제공하느 ㄴ기능이 아닌걸 사용하면 별도로 커스터마이징을 하면
entity Manager를 통해서 처리하면 된다. 

hibernate에서 엔티티 매니저는 세션이라고 부른다. 
세션은 영속성 컨텍스트를 관리하는 역할을 한다.

영속성 컨텍스트에서 영속성 매니저는 엔티티를 관리하느 ㄴ엔티티매니저가 있다. 
엔티티 매니저는 영속성 컨텍스트를 관리하는 세션과 같은 역할을 한다.

find를 통해서 캐시 역할을 하는걸 한번 보도록 해보자 

@Test
void cacheFindTest() {
    User user = userRepository.findById(1L).get();
    user.setName("martin2");
    userRepository.save(user);
    user.setEmail("martin2@gmail.com");

이렇게 해서 이메일을 조건으로 갖는 쿼리가 세번 호출된다.

cacheFindTest() {
findById(1L).get();
셀렉트 쿼리가 이렇게 실행된다. 이렇게 findById를 통해 가져오면 
셀렉트 쿼리가 한번 두번 세번 실행되는데 이렇게 되는 이유는
처음에는 영속성 컨텍스트에 캐시가 없기 때문에 셀렉트 쿼리를 실행하고
두번째는 영속성 컨텍스트에 캐시가 있기 때문에 셀렉트 쿼리를 실행하지 않고
영속성 컨텍스트에 있는 캐시를 가져오기 때문에 셀렉트 쿼리가 실행되지 않는다.

@Transactional 어노테이션을 넣으면 
조회시에 영속성 컨텍스트내에 존재하는 엔티티 케시에서 직접 처리한 것을 알 수 있다 .
진짜 디비에서 하지 않고 영속성 컨텍스트 내에서 자동으로 캐시 처리하는 것을 
jpa의 일차 캐시라고 이야기한다. 

그렇다면 findbyid findbyemail 일차 캐시가 적용되고 안되고 차이는 뭘까
findbyid는 영속성 컨텍스트 내에 캐시가 존재하기 때문에 캐시를 가져오고
findbyemail은 영속성 컨텍스트 내에 캐시가 존재하지 않기 때문에 캐시를 가져오지 않는다.

아이디로 조회하게 되면 영속성 컨텍스트 내에 존재하는 일차 캐시에 엔티티가 있는지 확인해보고 
있으면 db 조회 없이 바로 값을 가져오고 없으면 db 조회를 하게 된다.
실제 쿼리로 db조회를 해서 결과값을 1차 캐시에 한번 저장하고 보여준다. 

아까전에 transactional 어노테이션을 넣어서 테스트를 진행했는데

실제로 프린트는 네번찍혀ㅑㅆ다 
transactional 1차 캐시에 적용이 안됬기 때문이다. 
이렇게 넣으면 
id값을 통해서 1차 캐시가 동작하게 된다.
jpa 조회 성능이 올라가게 된다. 직접 id값을 통해서 조회하느 ㄴ경우는 드문 편이긴 한다. 
그렇지만 jpa 특성상 id값을 조회한 조회가 매우 빈번하게 일어난다. 
업데이트나 딜리트 쿼리를 사용하게 되면 기본적인 id값에 대한 조회가 빈번하게 일어나니깐
1차 캐시를 사용함으로써 

영속성 컨텍스트 내의 캐시를 이해하게 되면 flush의 메소드의 역할도 이해할 수 있게 된다. 

특정 시점에 아직 db에 반영되지 않은 경우가 생기기 때문이다 그렇기에 영속성 컨텍스트가 flusg되서
db에 동기화 되는 일은 언제일까
flush될때 db에 동기화가 된다.
이건 개발자가 의도적으로 되는 것 자동이 아님 
영속성 컨텍스트에서 보이는 데이터와 db가 동기화 된다 .
코드를 조금 보면 
flush를 제거하고 email save하고 flush를 제거해보고 
sout  하고 userRepository.findById(1L).get());
이렇게 하면
userRepository.flush();

sout    2번째  findbyId 하고 테스트를 실행시켜주면 
업데이트 처리 된 것처럼 보여진다. 
영속성 컨텍스트에서 가지고 있는 값과 실제 db에서 있는 값이 다르면 
flush를 하면 
업데이트를 하고 db에 반영이 된다. 업데이트가 ㅊ

flush 메소드를 호출하게 되면 의도적으로 영속성 캐시를 데이터베이스에 동기화하는 작업들을 처리하게 된다. 

트렌잭션이 종료될 경우이다. save의 실제 구현체를 보면 트랜잭셔널이 걸려있다. 
전체 로직에 대해서 트랜잭셔널을 안 걸면 해당 라인이 반영된다 그때그때 반영된다. 
자동으로 flush가 일어나기 때문에 로직에 

findAll을 하면 엔티티매니저는 어떻게 해야될까 쓰기 지연이 발생해서 
db에 있는 데이터가 반영하지 않았고 select * from user 전체 유저를 영속성 컨텍스트로 가져오게 될 
것이다. 지금에서 1이라는 데이터는 저장된 값이 있는데 
이 값이 좀 더 최신의 데이터이기때문에 id 1인 케이스는 영속성 캐시와 db데이터를 비교해서 
더 최신의 영속성 캐시 값을 사용하고 나머지는 db에 있는 값을 가져올 것이다. 

내가 jpa개발자라면 이런 merge 과정을 어떻게 코딩할 것이냐 
데이터를 merge 하는 과정은 영속성 캐시에 있는 값을 flush해주고 
두곳의 데이터를 비교하지말고 
db쪽으로 다 반영하고 db데이터를 조회해서 가져오는 방식이다. 
이렇게 하면 영속성 캐시에 있는 값과 db에 있는 값을 비교하지 않아도 되기 때문에
성능상으로 더 좋다.

업데이트 쿼리가 동작을 하고 

flush 메소드르 명시적으로 호출하느 ㄴ시점 아니면 끝나는 시점 아니면 
복잡한조건에 jpql이 실행되는 시점 

영속성 캐시는 영속성 컨텍스트의 큰 틀이자 핵심이다.
엔티티 매니저가 엔티티 생명주기 알아보자 

앞에서 얘기했던 영속성 컨텍스트에서 가장 주체가 되는 클래스느 ㄴ엔티티 매니저 객체이다. 
엔티티는 하나의 객체이기 때문에 엔티티와 db레코드 사이에 어떻게 연결해주고 어떻게 반영하는지 
엔티티 매니저의 역할이다. 

엔티티 매니저가 엔티티의 상태를 어떻게 변화시키는지 학습해보자 
엔티티 라이프 사이클이라고 하면 4가지 상태가 존재한다. 
trasient 상태 영속상태 managed 상태 준영속 상태 detached 상태가 있다.

trasient 상태는 엔티티 객체를 생성한 상태이다.
영속상태는 엔티티 매니저를 통해서 엔티티를 영속성 컨텍스트에 저장한 상태이다.
managed 상태는 영속성 컨텍스트에 의해 관리되는 상태이다.
준영속 상태는 영속성 컨텍스트에 저장되었다가 분리된 상태이다.
detached 상태는 영속성 컨텍스트에 저장되었다가 분리된 상태이다.

엔티티 어노테이션 중에서 @Id는 식별자를 매핑할 때 사용한다.
transient 상태는 엔티티 객체를 생성한 상태이다.
transient 어노테이션이란 엔티티 객체를 생성한 상태이다.
영속성 컨텍스트와 전혀 관계가 없는 상태이다.

엔티티라고 보기보단 그냥 자바 코드로 취급이 된다. 
영속성 컨텍스트를 반영하게 되는 시점이 transactional이 끝나는 시점이다.

서비스 패키지를 하나 만들고 
UserService를 만들어주고
@Service
public class UserService {
    @Autowired
    private UserRepository userRepository;

    @Transactional
    public void put() {
        User user = new User();
        user.setName("newUser");
        user.setEmail("newUser@fastcampus.com");
        
유저는 아직 비 영속 상태이다. 

UserServiceTest {
    @Autowired
    private UserService userService;

    @Autowired
    private UserRepository userRepository;

    @Test
    void test() {
        userService.put();
        System.out.println(">>> " + userRepository.findByEmail("newUser@fastcampus.com"))

이렇게 해서 실행시키게 되면 실제로 테스트에서는 셀렉트 쿼리가 
셀렉트 쿼리가 동작하지마 ㄴ값이 동작하지 않는다. 
db데이터가 연결이 된게 아니라 자바 객체로만 있다가 메소드가 종료되면 쓸모없기때문에 gc를 통해 
사라지는 데이터가 된다. 
그래서 이 상태는 비 영속 상태이다. 
사실상 영속 상태라는 것은 해당 엔티티가 영속성 컨텍스트의 관리하에 존재하는 상태라고 보면 된다.

@Autowired
private EntityManager entityManager;

@Autowired
private UserRepository userRepository;
userRepository.save(user);
세이브를 실행시켜줘도 영속화 효과가 있다. 

entityManager.persist(user);
이렇게 해도 영속화 효과가 있다.

유저 레포지터리를 사용하지 않고 엔티티매니저를 직접 호출해서 사용해도 된다.
persist(user)를 실행하면 영속성 컨텍스트가 해당하는 상태 
해당데이터가 db에 잘 영속화 되었다는걸 알 수 있다. 

영속화를 해서 유저 엔티티를 매니지드 상태로 만들고 
user.setName("newUserAfterPersist");

변경 내용을 db에 적용해야 하는 시점 db에 적용하려고 볼때에 해당 snapshot과 
현재와 다르다면 코드가 없다 해도 반영해준다. 
dirtycheck를 사용하기 때문에 대량의 엔티티를 다루게 될 때에는 
성능 저하가 발생하기도 한다. 

다음엔 detached 상태에 대해서 알아보자 
detach는 메서드를 제공하고 있지 않다. 
굳이 영속성에서 분리하고 싶다면
entityManager.detach(user);
이렇게 해주면 된다.

user1.setName("marrrrrtin");
entityManager.merge(user1);
이렇게 해주면
user1.setName("marrrrrtin");
이렇게 해줘도 업데이트가 된다.
merge는 영속성 컨텍스트에 있는 데이터를 가져와서
user1.setName("marrrrrtin");
이렇게 해주면

엔티티 객체에 생애 주기 즉 라이프 사이클에 대해서 알아봤다. 
영속 준영속 비영속 삭제 이런식으로 되어 있다. 영속성 컨텍스트가 각각의 컨텍스트를 관리하는지 
알 수 있다. 

변경 감지 더티 체크 조회에 대해서 밀착 캐시를 지원하고 있고 쓰기지원 
쓰기 지연이라는 기능을 지원하고 있다.

하지만 반면에 신경쓰지 않았던 동작으로 인해서 개발자가 의도하지 않았던 동작을 일으키기도 한다. 

트랜잭션이란 db의 명령어들의 논리적인 묶음이라고 생각하면 된다
트랜잭션은 all or nothing이다.
트랜잭션이란 db의 명령어들의 논리적인 묶음이다.
트랜잭션은 all or nothing이다.

트랜잭션의 특징은 원자성, 일관성, 격리성, 지속성이 있다.
원자성은 트랜잭션의 작업이 부분적으로 실행되다가 중단되지 않는 것을 보장하는 것이다.
일관성은 트랜잭션이 실행을 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태로 변환하는 것이다.
격리성은 동시에 실행되는 트랜잭션들이 서로에게 영향을 미치지 않도록 격리시키는 것이다.

트랜잭션은 모든 부분이 잘 이루어 지는걸 말한다. 

트랜잭션 내 데이타 조작에 대해선 다른 트랜잭션에 대해 독립적인 속성을 가진다. 
내가 친구에게 돈을 보내고 있는 중에 송금 트랜잭션이 완료되지 않았는데 친구 통장에서 
돈이 먼저 인출된다는 일이 일어나면 안된다. 

지속성이다. 데이터는 영구적으로 보관된다 라는뜻

ACID란 원자성, 일관성, 격리성, 지속성을 말한다.

@Service
public class BookService {
@Autowired
private BookRepository bookRepository;
@Autowired
private AuthorRepository authorRepository;

요즘엔 Autowired를 하지 않고 생성자를 통해서 주입을 해주는게 좋다.
@Autowired
public BookService(BookRepository bookRepository, AuthorRepository authorRepository) {
    this.bookRepository = bookRepository;
    this.authorRepository = authorRepository;
}
@RequiredArgsConstructor
public BookService(BookRepository bookRepository, AuthorRepository authorRepository) {
    this.bookRepository = bookRepository;
    this.authorRepository = authorRepository;
}

최근에는 필드 주입을 선호하고 있지 않다 생성자 주입을 하고 있다. 

public void put() {
    this.putBookAndAuthor();
}

  ㅏㅣ테스트에서 exception을 막기위해서     2ㄴㅇ

book은 저장이 된 상태 

이번에는 책과 저자를 저장하는 로직을 만들어보자 @Transactional을 붙여주면 디버그를 돌려보자 public void pubBookdAndAuthor()  {
    Book book = new Book();
    book.setName("JPA 시작하기");

    bookRepository.save(book);

    Author author = new Author();
    author.setName("martin");

    authorRepository.save(author);
}
일단 book을 실행해보면 empty transaction이라고 뜬다. select * from book; 여전히 empty이다 왜냐면 저장은 됬지만 커밋이 일어나지 안항ㅆ다. 
author까지하고 실행시키면 author도 저장이 되지 않은 상태이다. 그리고 끝까지 실행시키면 book이랑 author가 존재하지 않는다. 
transaction내에서 예외가 발생했기 때문에 save되었지만 커밋되지 않고 롤백이 되었다. 
트랜잭션은 all or nothing이다.

트랜잭션에 잘못된 사례에 대해서 소개하고 넘어가겠다. 첫번째는 checked exception 의 사용이다. 코드에선 억지로 exception을 발생시켰다. 

Book book = new Book();
book.setName("JPA 시작하기");

테스트에도 

isolation / propagtaion 에 대해서 알아보자 
isolation 은 트랜잭션에서 일관성이 없는 데이터를 허용하도록 하는 수준을 말한다.
propagation 은 트랜잭션에서 트랜잭션을 어떻게 전파할 것인지에 대한 옵션을 말한다.

트랜잭션 격리 단계는 트랜잭션에서 일관성 없는 데이터를 허용하도록 하는 수준을 말한다.
 enum을 보면 default, read_uncommitted, read_committed, repeatable_read, serializable 이렇게 있다.
default는 데이터베이스의 기본 격리 수준을 따른다.
read_uncommitted는 커밋되지 않은 데이터에 대한 읽기를 허용하는 수준이다.
read_committed는 커밋된 데이터만 읽기를 허용하는 수준이다.
repeatable_read는 트랜잭션이 완료될 때까지 SELECT 문장이 사용하는 모든 데이터에 shared lock이 걸리는 수준이다.
serializable는 트랜잭션이 완료될 때까지 SELECT 문장이 사용하는 모든 데이터에 shared lock이 걸리는 수준이다.

아래쪽으로 갈 수록 격리 단계가 강력해지고 그대신에 동시처리하는 수행 능력이 떨어진다. 
위쪽으로 갈 수록 일부 데이터의 정확성에 대해서 보장하지 못하는 경우가 간혹 생긴다. 단계 변화에 따라 어떤 현상이 있는지 살펴 보도록 하자. 

bookService.get(1L);
데이터베이스를 지우고 바로 테스트하기때문에 book.setName 정보가 1 일 것이기때문에 그렇다. 
bookRepository.findAll();;=

하나의 테스트 코드에서 경합시키는게 쉽지 않기 때문에 하나는 mysql 하나는  read_uncommitted로 해서 테스트를 진행해보자
커밋되지 않았는데 데이터를 읽어올 수 있음 
이런 케이스는 더티 리드라고 하는데 이 케이스가 왜 문제가 되냐면 
Book book = bookRepository.findById(id).get();
book.setName("바뀔까?"); 라고 하고 bookRepository.save(book); 을 해준다. 

read_committed는 커밋된 데이터만 읽기를 허용하는 수준이다나중에.
댠점은 커밋이 되지 않은 데이터는 읽지 못한다는 것이다.
이렇게 하면 더티 리드가 발생하지 않는다.

Repeatable_read는 트랜잭션이 완료될 때까지 SELECT 문장이 사용하는 모든 데이터에 shared lock이 걸리는 수준이다.
자기 트랜잭션이 시작될 때에 별도로 읽기 락을 걸어서 다른 트랜잭션이 해당 데이터를 수정하는 것을 막는다.
트랜잭션이 완전히 종료가 되고 완전히 밖으로 나온 다음에 카테고리 값이변경되어 노출된 것을 확인할 수 있었다. 이 격리수준에는 무슨 문제가 있을까
이런 경우에는 phantom read가 발생할 수 있다.
phantom read란 트랜잭션 내에서 같은 쿼리를 두 번 실행했을 때, 첫 번째 쿼리에서 없던 데이터가 두 번째 쿼리에서는 나타나는 현상을 말한다.
이런 현상이 왜 생기냐면 트랜잭션 내에서 select 쿼리를 실행할 때마다 트랜잭션 내에서 데이터가 변경될 수 있기 때문이다.

@Modifying 
@Query(value = "update book set category='none'", nativeQuery = true)
void update();

왜 커스텀 쿼리를 사용하는지에는 나중에 알려주겠다. 


조회를 해서 와서 update를 시켜주는 방식이라 phantom read 를 하는게 어렵다 그래서 아얘 update 쿼리로 네이티브 쿠리로 진행하는 것이다. 
bookRepository.update();
자체적으로 업데이트를 처리해주도록 해보자 
터미널에 가서 start transaction 을 하고 insert into book('id', 'name', 'category') values (1, 'jpa', 'none'); 을 해준다.

트랜잭션 내에서 한개의 레코드를 확인했고 처리를 했으나 실제로는 2개가 업데이트 처리가 된 것이다. 
이래서 최고 수준의 격리 단계가 필요하다 
Isolation.SERIALIZABLE
커밋이 일어나지 않은 쿼리에 대해서 락을 생성한다. 
start transaction insert into book('id', 'name', 'category') values (1, 'jpa', 'none'); 을 해준다.
업데이트를 하지 않고 waiting 상태가 된다. 
터미널에서 commit을 하게 되면 
이미 값이 두개가 나오고 
사실은 값이 2개였으니깐 둘다 none으로 바뀌는걸 볼 수 있다 .다른쪽 트랜잭션이 끝날때까지 무조건 기다리다 처리하기 떄문에 데이터의 정확성은 사실상 100퍼센트
하지만 웨이팅이 길어져서 성능적으로는 안좋을 수 있다. 
격리수준에 대해선 db의 이론적인 바탕이 크다 . 

각각의 속성마다 어떤 차이점이 있는지 확인해봤다. 보통은 read_uncommitted를 사용하지 않는다.
Serializable은 격리수준이 가장 높지만 성능상으로는 떨어진다.
그래서 보통은 read_committed를 사용한다.
repeatable_read는 phantom read가 발생할 수 있다는 점을 유의해야 한다.

propagation은 트랜잭션에서 트랜잭션을 어떻게 전파할 것인지에 대한 옵션을 말한다.
enum을 보면 required, requires_new, nested, supports, not_supported, mandatory, never 이렇게 있다.

required는 기본값으로, 이미 진행 중인 트랜잭션이 있으면 해당 트랜잭션에 참여하고, 없으면 새로운 트랜잭션을 생성한다.
requires_new는 항상 새로운 트랜잭션을 생성한다.
nested는 이미 진행 중인 트랜잭션이 있으면 중첩된 트랜잭션을 생성한다.
supports는 이미 진행 중인 트랜잭션이 있으면 해당 트랜잭션에 참여하고, 없으면 트랜잭션 없이 진행한다.
not_supported는 트랜잭션 없이 진행한다.
mandatory는 이미 진행 중인 트랜잭션이 있으면 해당 트랜잭션에 참여하고, 없으면 예외를 발생시킨다.
never는 이미 진행 중인 트랜잭션이 있으면 예외를 발생시키고, 없으면 트랜잭션 없이 진행한다.

트랜잭션을 그냥 선언만 하고 그냥 propagation을 선언 안하면 require를 가진다. 
기존에 사용하던 트랜잭션이 있다면 그걸 사용하고 업승면 새로운 트랜잭션을 사용하겠다는 의미이다. 
어찌보면 가장 직관적인 전파 속성이다. 
트랜잭션이 필요한데 있으면 재활용을 하고 없으면 직접만들어 사용하겠다는 뜻이다. 

save가 required가 되어있을것이다. 
메서드에서 @Transactional을 선언하면 기본적으로 propagation이 required로 설정되어 있다.
각각 트랜잭션 처리가 되서 각각 처리가 될 것이다. 
트랜잭션이 잘 붙어있으면 전체가 트랜잭션이 잡히게 될 것이다. 
실제로 구현 코드를 들어가서 보게 되면 트랜잭셔널이 잡혀져 있다. 
그리고 default는 required가 default로 잡혀있다. 
default propagation으로 잡혀있기 떄문에

required_new 는 항상 새로운 트랜잭션을 생성한다. 
nested는 이미 진행 중인 트랜잭션이 있으면 중첩된 트랜잭션을 생성한다. 앞쪽에서 생성한 트랜잭션을 사용하고 뒤쪽에서 생성한 트랜잭션을 사용하게 된다.
만약에 authorService자체가 실패를 하게되면 Author는 롤백이 일어나는데 기존에 실행이 됬던 save에 대해선 commit이 일어나게 된다. 
이런 경우에는 nested를 사용하면 된다.
만약에 book이 실패하게 되면 동일한 트랜잭션을 사용하고 있기 때문에 같이 rollback이 일어나게 된다. 트랜잭션 하나로 두개를 살짝살짝 
건드려가며 사용하기 때문에 nested를 사용하면 된다.

required_new 처럼 두개의 트랜잭션을 사용하는게 아니기때문에 save point까지의 성공은 보장을 한다 라는 뜻이다. 














































