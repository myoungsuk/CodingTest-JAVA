### 12_08

API GW를 이용한 API proxy 실습
시간이 지나면 api를 활용할 수 있게 처리하는 방법에 대해서 배워보자 

NewSeriviceController
라우터 하위에다가 v1.0/서비스를 추가해준것 
time-service
uri
predicates:
- Path=/v1.0/time-service/**
- After=2021-08-12T00:00:00+09:00[Asia/Seoul]

newservice를 요청하게 되면 에러가 나오게 된다. 요청 전달이 안되는데 이유는 time-service가 없기 때문이다.
간단하게 yml파일로 설정하면 시간 처리를 해줄 수 있다. 
그 다음에 헤더매칭인데 
서버 투 서버 요청을 할 때는 헤더에 특정한 키값을 정의해서 헤더의 값이 일치하는 경우에만
허가해주게 
헤더 투 헤더 요청은 
헤더 값도 키 값 요청이 보이는데 인증성 데이터일 경우에느 ㄴ서버투 서버 방식으로 
설정할 수 있다. 
그 다음에는
헤더 투 헤더 요청을 해보자
헤더 투 헤더 요청은
헤더 값도 키 값 요청이 보이는데 인증성 데이터일 경우에는 서버투 서버 방식으로
설정할 수 있다.

-id : header-service
-uri : http://localhost:8080
-predicates:
- Path=/v1.0/header-service/**
- Header = X-Request-Id, \d+

헤더 서비스가 이렇게 헤더로 정의했을 때 맞지 않으면 요청이 제대로 전달되지 않게 된다. 
헤더 정보 없이 get으로 호출하게 되면 

글로벌 exception 핸들러에서 요청을 하면 response로 쏴주는 형채가 된다. 
공통 에러 처리도 실제로 쓰게 되는 부분중 하나인데 글로벌 에러처리를 고려해서 
에러처리응담을 json으로 전달할 수 있게 하면된다. 

유레카 사용 방법 
유레카는 서비스 디스커버리를 위한 서버이다.
서비스 디스커버리는 서비스를 찾아주는 역할을 한다.

디스커버리 패턴 
유레카 서버애를 추가해서 유레카 서버가 다른 api 서버들을 관리하는 것 
유레카 서버를 만들어서 포트를 8761로 설정하고
유레카 클라이언트 설정을 추가해서 둘이 서로 연겨로디도록 해보겠다. 

eureka:
server.enableSelfPreservation: false
instance:
hostname: localhost
prefer-ip-address: true
네트워크를 연결이 안되더라도 유지해주는 것 false;

eureka:
client:
register-with-eureka: false
fetch-registry: false
service-url:

클라우드를 많이 쓰는 회사들도 있지만 100프로 다 클라우드를 이용하는것보단 자사 
네트워크도 활용하는 편이다. 
l4 스위치나 l7스위치 이런걸 연결해서 사용하는 경우가 많다.

유레카는 별도로 설치해줘야되는ㄴ데 
사내 인프라에 zookeeper가 설치되어있으면 유레카를 설치할 필요가 없다.

쓰기 요청 분산을 하려면 어떻게 해야되는지 알아보자 
이번시간에 레빗mq라던지 카프카를 사용하면서 쓰기요청 분산을 한번 해보도록 하자 
동영상 업로드를 할 때 저희가 하나의 서버로 말했었는데 
업로드 서버랑 게시글 조회 이미지 조회 서버 이렇게 분산하는게 첫번째

쓰기가 진행되고 나서 동영상을 업로드한 결과를 확인해야하는데 확인하는 부분에 있어서 
폴링인데 너무 비 효율적이니깐 

이벤트를 받아서 이벤트 드리븐 방식으로 처리할 수 있으면 레빗mq나 카프카 같은 메세지 브로커를 
사용하지 않으면 업로드 서버한테 물어봐야되는데 
이벤트를 받아서 이벤트 드리븐 방식으로 처리할 수 있으면 레빗mq나 카프카 같은 메세지 브로커를
사용하지 않으면 업로드 서버한테 물어봐야되는데

메세지 드리븐 방식으로 처리할 수 있게 된다.파일 업로드가 완료되면
완료된 파일 정보를 레빗 엠큐나 카프카에 적재된 큐룰 꺼내서 알 수 있다. 
왜쓰는지 알아야되니깐 

AMQP방식이 아니라 TCP/IP 방식인데 성능이 좋아서 kafka도 그런식으로 쓴다. 
카프카는 TCP/ip로 이벤트가 쌓이면 파일로 저장이 되는데 
레빗 엠큐는 AMQP방식으로 이벤트를 쌓는다.

스프링 카프카 라이브러리를 추가해서 작업 할 것
메세지 수신은 카프카 리스너 

스프링 AMQP를 이용한 rabbit mq 실습

레빗엠큐를 연동해야되니깐 우산 할 건 윈도의 사용자의 경우에는 WSL이라고해서 
리눅스를 사용할 수 있는 툴을 사용해야된다. 
Docker를 쓰기위해서 도커를 윈도우에 바로 쓰는게 아니라 윈도우의 서브 시스템으로 
리눅스를 사용할 수 있는 툴을 사용해야된다.
서버 시스템 리눅스 툴에 도커를 쓰는 것

WSL2된 사태에서 도커를 실행하면 도커 컨테이너들을 관리할 수 이;ㅆ다. 
윈도우 안에서 WSL리눅스를 쓰고있는 것 도 커 컴포즈 yml파일 은 공유가 되어있다. 
admin이 잘 떠있는지 확인

rabbitMQ 도커 파일 받고 

@EnableRabbit
RabbitMQConfig
큐틀을 매핑할 키값
클래스 매퍼는 객체를 주고 받을 것이니깐 객체로 사용할 값을 클래스 매퍼로 정의 할 수 있다. 

제이슨 컨버터 추가 설정 
rabbitConnectionFactory 실제로 연동하는 정보 
커넥션 객체를 만든 다음에 유저 정보 패스워드를 세팅하고 있다. 
그리고 rabbitAdmin 
큐 등록해주는 역할 


RabbitMessagePublisher
@Autowired

큐 탭을 클릭했ㅇㄹ 때타입이 topic 4 개의 큐들이 등록이 되어있고 
exchanges에도 타입이 topic 으로 등록되어있다. 

리소스에 도커에 같은걸로 띄우고있다. 15672번 포트로 접속하면 된다.
이건 admin용 포트이다. 자바로 연동 통신할 때는 5672번 포트를 사용한다.

sendMSg RabbitMQReceiver djshxpdltusdmf tkdydgksms qkdqjq 
방법 photo.sample

spring.kafka.consumer:
bootstrap-servers:127.0.0.1:9092
group-id: group_id
auto-offset-reset: earliest
enable-auto-commit: false

컨슈머 기본 세팅으로 
실제로 메세지를 보내는것으로 확인해보자
간단하게 이런거는 MyEvent를 만들어서  게터 세터 만들어주고 
private String eventId;
private Map<String, Object> eventData;

@ToString
메세지를 전송하는 애를 만들어서 sender 패키지에 KafkaProducer 클래스를 만들고 
@Component
public class KafkaProducer {
public static final String TOPIC_NAME = "thecodinglive";

스프링 카프카 설명 처음에  카프카 템플릿이 있었는데 
레빗도 레빗템플릿으로 보내고 

규칙을 찾아서 보내는걸 봐야된다. 
메시지 보내는 건 항상 무슨 무슨 템플릿 카프카도 카프카 템플릿으로 메시지를 보내고 
추천하는 방식은 카프카를 안쓰게 될 수도있고 레빗엠큐를 안쓸 수도있는데 
사용하는 측면에 맞춰서 생각하보면 클라이언트 라이브로 스프링에서 제공하는 라이브러리에서
공통점을 찾아내고 잘 적용할 수 있느 ㄴ방법을 생각해보는게 좋은 것 같다. 

카프카나 레빗엠큐도 따로 공부할만큼 양이 많다. 
혼자서 언제든지 테스트할수있는 본ㅇ

@Autowired
private KafkaTemplate<String, MyEvent> kafkaTemplate;

public void send(String topic, Object data) {
카프카 템플릿에서 String String
실제로 보낼땐 json 문자열로 보내면 되서 stirng string으로 한 것이다. 
좀 더 단수낳게 생각하면 send 메소드 바깥쪽에선 테이터 타입을 주고받게하고 실제로 
카프카랑 연동되는 단계에선 String문자로 들어가게 하면

데이터 전송역할을 하는 클래스가 벼ㄱㄴ경되도 클래스 자체로 직렬화하는것보단 문자로 하는게 안전

kafkaTemplate.send(topic, JacksonConverter.toJson(data));
}

프로듀서를 만들었으니깐 수신하는 애도 컴포넌트로 등록을 해주면 된다. 
@RabiitListener // rabbitmq

카프카도 똑같이 
@KafkaListener(topics = KafkaProducer.TOPIC_NAME)
KafkaProducer.

@RestController
QuickController

restapi

@GetMapping("/dummy")
public String dummy() {
return "{}";
}

swagger-ui.html

@GetMapping("/dummy")
public String getMember(@RequestParam("empNo") String empNo) {
return "{}";
}

emp 넘버는 1,2,3,4,5
String empNo, @RequestParam("year") int year) {
log.info("empNo: {}, year: {}", empNo, year);
return "ok";
}

@GetMapping("/company/{id}")
public String getCompany(@PathVariable("id") String id) {
































