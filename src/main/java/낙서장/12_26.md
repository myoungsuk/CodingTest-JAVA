### 12 26

KQL 문법
필드명 *
필드명:값
필드명:값 AND 필드명:값
필드명:값 OR 필드명:값

특정 필드의 값이 일치하는지 
필드명:값

clientip : 172.155.

앞에 있는 헬로 월드는 토큰이 쪼개지면서 
뒤에있느 따음표있는 헬로 월드는 정확하게 따짐

묶지 않았다면 coming up 도 찾겠지만 아닌것도 찾고 있다. 
따옴표가 묶인것과 아닌걸 찾고 있다. 

로그에 bytes라는 필터가 있다. 
특정 타입의 값은 범위를 이용해서 필터링 가능 
bytes : [1000 TO 2000]

정규화시 고려해야하느것
얼마나 빠르게 데이터의 최신성을 보장해야하나
객체의 탐색 깊이가 얼마나 깊은가?
A->B->C->D->E->F->G->H->I->J->K->L->M->N->O->P->Q->R->S->T->U->V->W->X->Y->Z
객체의 탐색 깊이가 깊다면 정규화를 하지 않는것이 좋다.
객체의 탐색 깊이가 얕다면 정규화를 해도 된다.

C의 D참조가 변경될 경우 
B의 D 참조도 같이 변경되어야 한다. 

읽기 성능을 위해서 쓰기 성능을 희생한 것

정규활르 하기로 했다면 읽기시 데이터를 어떻게 가져올 것인가 
테이블 조인을 활용하는데 사실 고민해볼 문제다. 
테이블 조인은 서로 다른 테이블의 결합도를 엄청나게 높인다 
조회시에는 성능이 좋은 별도 데이터베이스나 캐싱등 다양한 최적화 기법을 이용할 수 있다. 
조인을 사용하게 되면, 이른 기법들을 사용하는데 제한이 있거나 더 많은 리소스가 들 수 있다. 
읽기 쿼리 한번더 발생하는 것은 큰 부담이 아닐 수도 있다. 

데이터 더장 용도로는 디스크와 메모리를 활용한다. 
메모리는 디스크에 비해 빠르다. 영속성 측면에서 보면 전원이 공급되지 않으면 휘발 
디스는 데이터가 보존됨 
가격측면에서 메모리는 상대적으로 비쌈 

데이터베이스의 데이터는 결국 디스크에 저장된다. 
데이터 베이스 성능의 핵심은 데이터베이스가 디스크 접근을 최소화 시키는 것
메모리에 올라온 데이터로 최대한 요청을 처리하는것
메모리 캐시 히트율을 높이는 것

메모리 캐시 히트율을 높이는 방법
메모리에 올라온 데이터를 최대한 활용하는 것

메모리에 데이터 유실을 고려해 WAL를 사용한다. 
랜덤 I/O와 순차 I/O
랜덤 I/O는 디스크의 헤드가 움직이는 것

대부분의 트랙잭션은 무작위하게 Write가 발생
이를 지연시켜 랜덤 I/O 횟수를 줄이는 대신 순차적 I/O를 발생시켜 정합성을 유지ㅎ시킨다. 

pk 로 autoincrement vs UUID
autoincrement는 순차적으로 증가하는 값이기 때문에 순차적 I/O를 발생시키기 좋다.
UUID는 랜덤한 값이기 때문에 랜덤 I/O를 발생시키기 좋다.

클러스터 인덱스란
데이터를 저장할 때 인덱스를 기준으로 데이터를 정렬해서 저장하는 것
인덱스를 기준으로 데이터를 정렬해서 저장하기 때문에 인덱스를 기준으로 데이터를 조회할 때 빠르다.
 pk 가 정렬되어있어서 범위 검색이 매우 빠르다. 
공간적 캐시 이점을 누릴 수 있다. 
두번째로는 세컨더리 인덱스들이 pk를 가지고 있어 커버링에 유리 

2번 인덱스 찾아서 노드 찾아간다. 
보조 인덱스들은 pk를 들고있다. 
마지막으로 클러스터 인덱스는 데이터 위치를 결정하는 키값이다. 
MySQL pk는 클러스터 인덱스다
MySQL에서 pk를 제외한 모든 인덱스는 pk를 가지고 있다. 

회원 등록시 인증 
스프링 시큐리티 이용해서 회원 인증 
OAuth도 붙여보고 

PostReadService

@RequiredArgsConstructor
@Service
public class PostReadService {

    private final PostRepository postRepository;

    public Post readPost(Long id) {
        return postRepository.findById(id)
                .orElseThrow(() -> new PostNotFoundException(id));
    }
}

public void getDailyPostCount(Long memberId, LocalDate startDate, LocalDate endDate) {
    postRepository.countByMemberIdAndCreatedAtBetween(memberId, startDate, endDate);
}

public List<DailyPostCount> getDailyPostCounts(DailyPostCountRequest request) {
    return postRepository.getDailyPostCounts(request);
}

백만건정도 데이터 삽입하는 easyRandom을 사용해서 진행해볼 예정

멤버대신 포스트 도메인을 하나 ㅁㄴ들고 

public class PostBulkInsertTest {
    
        private static final int POST_COUNT = 1_000_000;
    
        private static final EasyRandom easyRandom = new EasyRandom();
    
        @Autowired
        private PostRepository postRepository;
    
        @Test
        void bulkInsert() {
            List<Post> posts = new ArrayList<>();
            for (int i = 0; i < POST_COUNT; i++) {
                posts.add(easyRandom.nextObject(Post.class));
            }
            postRepository.saveAll(posts);
        }
    }

PostFixtureFactory 
백만건정도의 레코드를 삽입하는 이유는 내가 쓴 캘린터를 조회할때 
인덱스를 활용해서 어떻게 개선할지 알아보자 

기존에 MemberFixtureFactory 파라미터의 주입 없이 무작위로 만들었지만 

멤버 아이디와 시작날자와 끝날자를 주입 받도록 할 것이다. 
factory로 가보면 

public class PostFixtureFactory {
    private static final EasyRandom easyRandom = new EasyRandom();

    public static Post createPost(Long memberId, LocalDate createdAt) {
        return easyRandom.nextObject(Post.class, "memberId", memberId, "createdAt", createdAt);
    }
}

var memberIdField = named("memberId")

public void bulkInsert(Long memberId, LocalDate startDate, LocalDate endDate) {
    List<Post> posts = new ArrayList<>();
    for (LocalDate date = startDate; date.isBefore(endDate); date = date.plusDays(1)) {
        for (int i = 0; i < POST_COUNT; i++) {
            posts.add(PostFixtureFactory.createPost(memberId, date));
        }
    }
    postRepository.saveAll(posts);
}

bulkinsert 기능이란
여러개의 레코드를 한번에 삽입하는 기능
구현하는방법
jdbc 사용하는경우 
PreparedStatement를 사용해서 여러개의 레코드를 삽입하는 방법
JPA를 사용하는 경우
EntityManager를 사용해서 여러개의 레코드를 삽입하는 방법

public void bulkInsert(List<Post> posts) {
var sql = "String.format("insert into post (member_id, title, content, created_at) values (%d, '%s', '%s', '%s')", post.getMemberId(), post.getTitle(), post.getContent(), post.getCreatedAt());
    jdbcTemplate.batchUpdate(sql);
}
배치 업데이트란
여러개의 쿼리를 한번에 실행하는 기능
구현하는 방법
jdbc를 사용하는 경우

jpa를 써도 jdbc 템플릿에 bulkInsert때문에 많이 사용한다. 

spring data jpa를 사용하면 saveall인데 세이브를 루프돌면서 돌고 
pk가 autoIncrement는 단건으로 진행되기때문에 
saveall은 성능이 좋지 않다.

백만건은 단건으로 돌리면 시간이 오래걸리기 때문에 
parallel로 돌릴것이다. 
a
var stopWatch = new StopWatch();
stopWatch.start();
stopWatch.stop();
sout    stopWatch.getTotalTimeSeconds();

db에 cpu가 얼마나 튀게 되는지 직접 볼 것이다. 
parrelelStream을 사용하면 cpu가 얼마나 튀는지 볼 수 있다.
쿼리 속도가 얼마나 걸리는지도 확인

stopWatch.start();
posts.parallelStream().forEach(postRepository::save);
stopWatch.stop();

var queryStopWatch.stop();;

sout    

부하 테스트 최적화 
api 부하 테스트 최적화 
객체 생성시간은 15초 db인서트는 100만건 

트랜잭션을 사용하면 테스트 코드 사용시에 롤백이 되기 때문에
데이터를 db에 넣고싶지 않으면 트랜잭션을 사용하는것







































